{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip -q install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "industry_size = 32\n",
    "product_name_size = 20\n",
    "product_category_size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMComponent(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(LSTMComponent, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        packed_input = pack_sequence(input, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "class RecommenderModel(nn.Module):\n",
    "    def __init__(self, industry_size, product_name_size, product_category_size, hidden_dim):\n",
    "        super(RecommenderModel, self).__init__()\n",
    "\n",
    "        self.product_name_size = product_name_size\n",
    "\n",
    "        self.industry_embedding = nn.Embedding(num_embeddings=industry_size, embedding_dim=32)\n",
    "        self.product_name_embedding = nn.Embedding(num_embeddings=product_name_size, embedding_dim=hidden_dim)\n",
    "        self.product_category_embedding = nn.Embedding(num_embeddings=product_category_size, embedding_dim=hidden_dim)\n",
    "        self.product_is_implemented_embedding = nn.Embedding(num_embeddings=2, embedding_dim=hidden_dim)\n",
    "\n",
    "        self.lstm = LSTMComponent(hidden_dim=hidden_dim * 3, output_dim=32)\n",
    "\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, product_name_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def expand_product_name_size(self, new_size):\n",
    "        new_embedding = nn.Embedding(new_size, self.product_name_embedding.embedding_dim)\n",
    "        new_fc = nn.Linear(32, new_size)\n",
    "        \n",
    "        new_embedding.weight.data[:self.product_name_embedding.num_embeddings] = self.product_name_embedding.weight.data\n",
    "        nn.init.normal_(new_embedding.weight.data[self.product_name_embedding.num_embeddings:])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            new_fc.weight[:self.fc2.out_features] = self.fc2.weight\n",
    "            new_fc.bias[:self.fc2.out_features] = self.fc2.bias\n",
    "            nn.init.normal_(new_fc.weight[self.fc2.out_features:])\n",
    "            nn.init.normal_(new_fc.bias[self.fc2.out_features:])\n",
    "        \n",
    "        self.product_name_embedding = new_embedding\n",
    "        self.fc2 = new_fc\n",
    "\n",
    "        self.product_name_size = new_size\n",
    "\n",
    "    def forward(self, industry, product_name, product_category, product_is_implemented, new_size):\n",
    "        if new_size > self.product_name_size:\n",
    "            self.expand_product_name_size(new_size)\n",
    "            \n",
    "        industry_embedded = self.industry_embedding(industry)\n",
    "        product_name_embedded = self.product_name_embedding(product_name)\n",
    "        product_category_embedded = self.product_category_embedding(product_category)\n",
    "        product_is_implemented_embedded = self.product_is_implemented_embedding(product_is_implemented)\n",
    "\n",
    "        product_embedded = torch.cat([product_name_embedded, product_category_embedded, product_is_implemented_embedded], dim=-1)\n",
    "\n",
    "        product = self.lstm(product_embedded)\n",
    "\n",
    "        combined = torch.cat([industry_embedded, product], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        output = output[:, :product_name_size]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderModel(\n",
    "    industry_size,\n",
    "    product_name_size,\n",
    "    product_category_size,\n",
    "    hidden_dim=256\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "industry_1 = torch.randint(0, industry_size, (batch_size,), device=device)\n",
    "product_1 = torch.randint(0, product_name_size, (batch_size, 2), device=device)\n",
    "product_2 = torch.randint(0, product_category_size, (batch_size, 2), device=device)\n",
    "product_3 = torch.randint(0, 2, (batch_size, 2), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3190, -0.0411,  0.0490,  0.0752, -0.3768, -0.0037,  0.0284, -0.2892,\n",
       "          0.1096, -0.0144,  0.1461, -0.1642,  0.1814, -0.2203, -0.3188, -0.2520,\n",
       "         -0.5617,  0.0086, -0.1564,  0.0943],\n",
       "        [-0.1503, -0.0540, -0.0074, -0.0605, -0.0053,  0.0902,  0.0708, -0.3153,\n",
       "         -0.1508,  0.2092, -0.1877,  0.0808, -0.3323, -0.2493,  0.0038, -0.2754,\n",
       "         -0.5922, -0.1885,  0.1346,  0.3654]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(industry_1, product_1, product_2, product_3, product_name_size)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2855, -0.2265,  0.1086,  0.2448, -0.3218, -0.0655,  0.0636, -0.1277,\n",
       "          0.0655,  0.0850,  0.2330, -0.0627,  0.0424, -0.0693, -0.3595, -0.2767,\n",
       "         -0.5317,  0.0483, -0.1427,  0.1119],\n",
       "        [-0.2494, -0.1548,  0.0594, -0.0022, -0.1253, -0.0537,  0.1882, -0.3427,\n",
       "         -0.1543,  0.0796, -0.1224,  0.0980, -0.1784, -0.3356, -0.0967, -0.3535,\n",
       "         -0.6304, -0.0629, -0.0027,  0.2383]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(industry_1, product_1, product_2, product_3, product_name_size+1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "industry = data[\"Industry\"].tolist()\n",
    "product_name = data[\"ProductName\"].tolist()\n",
    "product_category = data[\"ProductCategory\"].tolist()\n",
    "product_is_implemented = data[\"ProductIsImplemented\"].tolist()\n",
    "\n",
    "# class RecommenderDataset(Dataset):\n",
    "#     def __init__(self, input, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
