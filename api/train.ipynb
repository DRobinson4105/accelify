{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "# %pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 #comment if not using gpu\n",
    "%pip -q install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_NAME = \"model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "industry_size = 32\n",
    "product_name_size = 20\n",
    "product_category_size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMComponent(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(LSTMComponent, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        packed_input = pack_sequence(input, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "class RecommenderModel(nn.Module):\n",
    "    def __init__(self, industry_size, product_name_size, product_category_size, hidden_dim, padding_value=-1):\n",
    "        super(RecommenderModel, self).__init__()\n",
    "\n",
    "        self.product_name_size = product_name_size\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.industry_embedding = nn.Embedding(num_embeddings=industry_size+1, embedding_dim=hidden_dim, padding_idx=industry_size)\n",
    "        self.product_name_embedding = nn.Embedding(num_embeddings=product_name_size+1, embedding_dim=hidden_dim, padding_idx=product_name_size)\n",
    "        self.product_category_embedding = nn.Embedding(num_embeddings=product_category_size+1, embedding_dim=hidden_dim, padding_idx=product_category_size)\n",
    "        self.product_is_implemented_embedding = nn.Embedding(num_embeddings=3, embedding_dim=hidden_dim, padding_idx=2)\n",
    "\n",
    "        self.lstm = LSTMComponent(hidden_dim=hidden_dim * 3, output_dim=hidden_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, product_name_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def expand_product_name_size(self, new_size):\n",
    "        new_embedding = nn.Embedding(new_size, self.product_name_embedding.embedding_dim, padding_idx=self.padding_value)\n",
    "        new_fc = nn.Linear(32, new_size)\n",
    "        \n",
    "        new_embedding.weight.data[:self.product_name_embedding.num_embeddings] = self.product_name_embedding.weight.data\n",
    "        nn.init.normal_(new_embedding.weight.data[self.product_name_embedding.num_embeddings:])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            new_fc.weight[:self.fc2.out_features] = self.fc2.weight\n",
    "            new_fc.bias[:self.fc2.out_features] = self.fc2.bias\n",
    "            nn.init.normal_(new_fc.weight[self.fc2.out_features:])\n",
    "            nn.init.normal_(new_fc.bias[self.fc2.out_features:])\n",
    "        \n",
    "        self.product_name_embedding = new_embedding\n",
    "        self.fc2 = new_fc\n",
    "\n",
    "        self.product_name_size = new_size\n",
    "\n",
    "    def forward(self, industry, product_name, product_category, product_is_implemented, new_size):\n",
    "        if new_size > self.product_name_size:\n",
    "            self.expand_product_name_size(new_size)\n",
    "\n",
    "        industry_embedded = self.industry_embedding(industry)\n",
    "        product_name_embedded = self.product_name_embedding(product_name)\n",
    "        product_category_embedded = self.product_category_embedding(product_category)\n",
    "        product_is_implemented_embedded = self.product_is_implemented_embedding(product_is_implemented)\n",
    "\n",
    "        product_embedded = torch.cat([product_name_embedded, product_category_embedded, product_is_implemented_embedded], dim=-1)\n",
    "\n",
    "        product = self.lstm(product_embedded)\n",
    "\n",
    "        combined = torch.cat([industry_embedded.squeeze(), product], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        output = output[:, :self.product_name_size]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 2\n",
    "# industry_1 = torch.randint(0, industry_size, (batch_size,), device=device)\n",
    "# product_1 = torch.randint(0, product_name_size, (batch_size, 2), device=device)\n",
    "# product_2 = torch.randint(0, product_category_size, (batch_size, 2), device=device)\n",
    "# product_3 = torch.randint(0, 2, (batch_size, 2), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model(industry_1, product_1, product_2, product_3, product_name_size)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model(industry_1, product_1, product_2, product_3, product_name_size+1)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"additional_data.json\", \"r\") as file:\n",
    "    info = json.load(file)\n",
    "\n",
    "product_name_map = {k: v for v, k in list(enumerate(info[\"Product_Names\"]))}\n",
    "product_name_len = len(product_name_map)\n",
    "product_category_map = {k: v for v, k in list(enumerate(info[\"Product_Categories\"]))}\n",
    "product_category_len = len(product_category_map)\n",
    "industry_map = {k: v for v, k in list(enumerate(info[\"Industries\"]))}\n",
    "industry_len = len(industry_map)\n",
    "\n",
    "print(product_name_len, product_category_len, industry_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.json\", \"r\") as file:\n",
    "    data = json.load(file)[\"Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderDataset(Dataset):\n",
    "    def __init__(self, data, product_name_len, product_category_len, device=\"cpu\"):\n",
    "        self.industries = torch.tensor([[industry_map[x[\"Input\"][\"Industry\"]]] for x in data]).to(device)\n",
    "\n",
    "        self.product_names = [torch.tensor([product_name_map[y[\"ProductName\"]] for y in x[\"Input\"][\"Products\"]]) for x in data]\n",
    "        self.product_names = pad_sequence(self.product_names, batch_first=True, padding_value=product_name_len).to(device)\n",
    "\n",
    "        self.product_categories = [torch.tensor([product_category_map[y[\"ProductCategory\"]] for y in x[\"Input\"][\"Products\"]]) for x in data]\n",
    "        self.product_categories = pad_sequence(self.product_categories, batch_first=True, padding_value=product_category_len).to(device)\n",
    "\n",
    "        self.product_is_implemented = [torch.tensor([y[\"IsImplemented\"] for y in x[\"Input\"][\"Products\"]]).long() for x in data]\n",
    "        self.product_is_implemented = pad_sequence(self.product_is_implemented, batch_first=True, padding_value=2).to(device)\n",
    "\n",
    "        self.output = [torch.tensor([product_name_map[y] for y in x[\"Output\"]]).long() for x in data]\n",
    "        self.output = pad_sequence(self.output, batch_first=True, padding_value=product_name_len).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.product_names.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.industries[index], self.product_names[index], self.product_categories[index], self.product_is_implemented[index], self.output[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = int(0.8 * len(data))\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "train_dataset = RecommenderDataset(data[:TRAIN_TEST_SPLIT], product_name_len, product_category_len, device)\n",
    "test_dataset = RecommenderDataset(data[TRAIN_TEST_SPLIT:], product_name_len, product_category_len, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderModel(\n",
    "    industry_len,\n",
    "    product_name_len,\n",
    "    product_category_len,\n",
    "    hidden_dim=256\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "train_loss_values = []\n",
    "test_loss_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    avg_train_loss, avg_test_loss = 0, 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for X1, X2, X3, X4, y in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(X1, X2, X3, X4, product_name_len)\n",
    "\n",
    "        target = torch.zeros((y.shape[0], product_name_len))\n",
    "\n",
    "        for i in range(y.shape[0]):\n",
    "            target[i, y[y < product_name_len]] = 1\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        avg_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X1, X2, X3, X4, y in test_dataloader:\n",
    "            output = model(X1, X2, X3, X4, product_name_len)\n",
    "\n",
    "            target = torch.zeros((y.shape[0], product_name_len))\n",
    "\n",
    "            for i in range(y.shape[0]):\n",
    "                target[i, y[y < product_name_len]] = 1\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            avg_test_loss += loss.item()\n",
    "\n",
    "    \n",
    "    avg_train_loss /= len(train_dataloader)\n",
    "    avg_test_loss /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Train Loss: {avg_train_loss} | Test Loss: {avg_test_loss}\")\n",
    "    \n",
    "    train_loss_values.append(avg_train_loss)\n",
    "    test_loss_values.append(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=model.state_dict(), f=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(range(epochs), train_loss_values, label=\"Train\")\n",
    "plt.plot(range(epochs), test_loss_values, label=\"Test\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
